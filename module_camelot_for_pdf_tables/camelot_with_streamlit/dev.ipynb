{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f27a189-1e64-4957-918b-411ec3e05c2a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a465f2fc-0119-41a8-8c42-77e6043f0f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:49.493622Z",
     "iopub.status.busy": "2024-04-18T18:38:49.493622Z",
     "iopub.status.idle": "2024-04-18T18:38:49.501665Z",
     "shell.execute_reply": "2024-04-18T18:38:49.501520Z",
     "shell.execute_reply.started": "2024-04-18T18:38:49.493622Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time_start_notebook = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd333e36-2a05-423e-8895-b22079e893aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:49.502484Z",
     "iopub.status.busy": "2024-04-18T18:38:49.502484Z",
     "iopub.status.idle": "2024-04-18T18:38:49.509539Z",
     "shell.execute_reply": "2024-04-18T18:38:49.509539Z",
     "shell.execute_reply.started": "2024-04-18T18:38:49.502484Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import pypdf\n",
    "from PyPDF2 import PdfReader\n",
    "from pypdf import PdfWriter\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings,AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import streamlit\n",
    "import streamlit as st\n",
    "import base64\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import openai\n",
    "import langchain\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "#--- ocr\n",
    "import pdf2image\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c92443-bcab-48eb-8958-e5563f98f815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:49.510537Z",
     "iopub.status.busy": "2024-04-18T18:38:49.509539Z",
     "iopub.status.idle": "2024-04-18T18:38:49.513713Z",
     "shell.execute_reply": "2024-04-18T18:38:49.513713Z",
     "shell.execute_reply.started": "2024-04-18T18:38:49.510537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fa88539-f419-4207-a6ee-bef2cf2dce1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:49.514713Z",
     "iopub.status.busy": "2024-04-18T18:38:49.514713Z",
     "iopub.status.idle": "2024-04-18T18:38:50.595976Z",
     "shell.execute_reply": "2024-04-18T18:38:50.595976Z",
     "shell.execute_reply.started": "2024-04-18T18:38:49.514713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.0 from C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\pip (python 3.11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06964bec-25e9-4673-91f7-006419f3dc32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.595976Z",
     "iopub.status.busy": "2024-04-18T18:38:50.595976Z",
     "iopub.status.idle": "2024-04-18T18:38:50.618763Z",
     "shell.execute_reply": "2024-04-18T18:38:50.618763Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.595976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain  : 0.1.16\n",
      "sys        : 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]\n",
      "streamlit  : 1.33.0\n",
      "openai     : 1.22.0\n",
      "pdf2image  : 1.17.0\n",
      "pypdf      : 4.2.0\n",
      "numpy      : 1.26.4\n",
      "pandas     : 1.5.3\n",
      "pytesseract: 0.3.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec0c90-8251-4477-b107-7ed8ee81c7c1",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f53d7c98-24d5-4ffe-aba5-8d47805ee999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.618763Z",
     "iopub.status.busy": "2024-04-18T18:38:50.618763Z",
     "iopub.status.idle": "2024-04-18T18:38:50.622690Z",
     "shell.execute_reply": "2024-04-18T18:38:50.622386Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.618763Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path_pdf_ocr = r\"C:\\Users\\a126291\\OneDrive - AmerisourceBergen(ABC)\\data\\pdf_files\\ocr_pdf\\screenshot_pages_eylea.pdf\"\n",
    "path_pdf_non_ocr = r\"C:\\Users\\a126291\\OneDrive - AmerisourceBergen(ABC)\\data\\pdf_files\\fda_drugs\\fda_eylea.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40084d-1c7a-4ce7-b7f2-01d9b417fb10",
   "metadata": {},
   "source": [
    "# source directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f969aec-c2ff-439c-9ece-18ccf1a6e339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.623330Z",
     "iopub.status.busy": "2024-04-18T18:38:50.623330Z",
     "iopub.status.idle": "2024-04-18T18:38:50.636755Z",
     "shell.execute_reply": "2024-04-18T18:38:50.636755Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.623330Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.isdir('src'):\n",
    "    shutil.rmtree('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37f97200-0abc-49b9-a6a6-e17573cec265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.636755Z",
     "iopub.status.busy": "2024-04-18T18:38:50.636755Z",
     "iopub.status.idle": "2024-04-18T18:38:50.642421Z",
     "shell.execute_reply": "2024-04-18T18:38:50.642421Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.636755Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('src'):\n",
    "    os.makedirs('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1ba5ec0-61ac-483e-a81c-4e2af996591d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.643383Z",
     "iopub.status.busy": "2024-04-18T18:38:50.643383Z",
     "iopub.status.idle": "2024-04-18T18:38:50.649877Z",
     "shell.execute_reply": "2024-04-18T18:38:50.649877Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.643383Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('src/__init__.py','w') as fh:\n",
    "    fh.write('# Author: Bhishan Poudel\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64298e81-11f8-4b56-a6ed-5238c4c27248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.651460Z",
     "iopub.status.busy": "2024-04-18T18:38:50.651460Z",
     "iopub.status.idle": "2024-04-18T18:38:50.867047Z",
     "shell.execute_reply": "2024-04-18T18:38:50.867047Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.651460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "!ls src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d5a486d-cb06-428e-a898-d7fa98373648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:50.868084Z",
     "iopub.status.busy": "2024-04-18T18:38:50.867047Z",
     "iopub.status.idle": "2024-04-18T18:38:51.098185Z",
     "shell.execute_reply": "2024-04-18T18:38:51.098185Z",
     "shell.execute_reply.started": "2024-04-18T18:38:50.868084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Author: Bhishan Poudel\n"
     ]
    }
   ],
   "source": [
    "!cat src/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffa1a2-a568-405e-babe-60b8ff2e59e1",
   "metadata": {},
   "source": [
    "# util: config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eda512f-9bc4-4d35-b17e-f4757af57f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:51.099191Z",
     "iopub.status.busy": "2024-04-18T18:38:51.099191Z",
     "iopub.status.idle": "2024-04-18T18:38:51.104327Z",
     "shell.execute_reply": "2024-04-18T18:38:51.104327Z",
     "shell.execute_reply.started": "2024-04-18T18:38:51.099191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/config.py\n",
    "\n",
    "def get_config():\n",
    "    # config\n",
    "    openai_api_key = \"f4001c4b49a845309d386e9014b7ae6b\"\n",
    "    openai_api_base = \"https://qa.gai.cencora.com/aoai\"\n",
    "    azure_endpoint = openai_api_base\n",
    "    openai_api_version = \"2023-03-15-preview\"\n",
    "    openai_api_type = \"azure\"\n",
    "\n",
    "    openai_deployment_name = \"gpt-35-turbo-16k\"\n",
    "    openai_model_name      = \"gpt-35-turbo-16k\"\n",
    "\n",
    "    # os environments\n",
    "    import os\n",
    "    os.environ['OPENAI_API_TYPE'] = openai_api_type\n",
    "    os.environ['OPENAI_API_VERSION'] = openai_api_version\n",
    "    os.environ['OPENAI_API_BASE'] = openai_api_base\n",
    "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "    # openai environments\n",
    "    import openai\n",
    "    openai.api_key = openai_api_key\n",
    "    openai.api_type = openai_api_type\n",
    "    openai.api_base = openai_api_base\n",
    "    openai.api_version = openai_api_version\n",
    "    openai.api_key = openai_api_key\n",
    "\n",
    "    config = {\n",
    "    'openai_api_base': openai_api_base,\n",
    "    'openai_api_version': openai_api_version,\n",
    "    'deployment_name': openai_deployment_name,\n",
    "    'model_name': openai_model_name,\n",
    "    'openai_api_key': openai_api_key,\n",
    "    'openai_api_type': openai_api_type\n",
    "    }\n",
    "\n",
    "    return config\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5e2523d-0200-4db2-affe-3dec358b8b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:51.105839Z",
     "iopub.status.busy": "2024-04-18T18:38:51.105531Z",
     "iopub.status.idle": "2024-04-18T18:38:51.110280Z",
     "shell.execute_reply": "2024-04-18T18:38:51.109776Z",
     "shell.execute_reply.started": "2024-04-18T18:38:51.105839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-35-turbo-16k'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import config\n",
    "\n",
    "config['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891c24a-b7cf-4762-9036-e066bd254d56",
   "metadata": {},
   "source": [
    "# Util: ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "900fab76-b66a-4185-883b-4a4ed790747c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:51.111285Z",
     "iopub.status.busy": "2024-04-18T18:38:51.110280Z",
     "iopub.status.idle": "2024-04-18T18:38:51.117083Z",
     "shell.execute_reply": "2024-04-18T18:38:51.116766Z",
     "shell.execute_reply.started": "2024-04-18T18:38:51.111285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_ocr.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_ocr.py\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "#--- ocr\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "pytesseract.tesseract_cmd = r\"C:\\Users\\a126291\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "#@st.cache_data\n",
    "def get_ocr_lst_text_from_uploaded_file(uploaded_file, language='eng',pytesseract_path=None):\n",
    "    import pdf2image\n",
    "    import pytesseract\n",
    "    from pathlib import Path\n",
    "\n",
    "    if pytesseract_path == None:\n",
    "        pytesseract_path = r\"C:\\Users\\a126291\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "    pytesseract.tesseract_cmd = pytesseract_path\n",
    "\n",
    "    try: # streamlit uploded file\n",
    "        data_bytes = uploaded_file.getvalue()\n",
    "    except:\n",
    "        try: # regular file path\n",
    "            path_pdf = Path(uploaded_file)\n",
    "            if path_pdf.exists():\n",
    "                with open(path_pdf, 'rb') as file:\n",
    "                    data_bytes = file.read()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    pil_images = pdf2image.convert_from_bytes(data_bytes)\n",
    "    lst_txt = []\n",
    "    for pil_image in pil_images:\n",
    "        text_one_page = pytesseract.image_to_string(pil_image, lang=language)\n",
    "        lst_txt.append(text_one_page)\n",
    "    return lst_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55d25337-5793-4cfd-a24f-740eb9e99bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:51.117083Z",
     "iopub.status.busy": "2024-04-18T18:38:51.117083Z",
     "iopub.status.idle": "2024-04-18T18:38:59.597759Z",
     "shell.execute_reply": "2024-04-18T18:38:59.597759Z",
     "shell.execute_reply.started": "2024-04-18T18:38:51.117083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croliters) admuistered by\n",
      "intravitreal injection every 4 weeks (monthly) for the frst 5 imjections, followed by 2 mg\n",
      "\n",
      "(0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may be\n",
      "dosed as frequently as 2 mg every 4 weeks (monthly), additional efficacy was not demonstrated\n",
      "10 most patients when EYLEA was dosed every 4 weeks compared to every 8 weeks [see\n",
      "Clinical Studies (14.4)]. Some patients may need every 4 week (monthly) dosing after the firs\n",
      "20 weeks (5 months).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.util_ocr import get_ocr_lst_text_from_uploaded_file\n",
    "\n",
    "path_pdf = path_pdf_ocr\n",
    "lst_text = get_ocr_lst_text_from_uploaded_file(uploaded_file=path_pdf, language='eng',pytesseract_path=None)\n",
    "\n",
    "print(lst_text[0][-500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1137d3b-1e7f-4efe-9355-77cb4e6445c2",
   "metadata": {},
   "source": [
    "# Util: Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca2ef8e2-4c34-4120-ae30-f748d5092e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:59.597759Z",
     "iopub.status.busy": "2024-04-18T18:38:59.597759Z",
     "iopub.status.idle": "2024-04-18T18:38:59.603790Z",
     "shell.execute_reply": "2024-04-18T18:38:59.603790Z",
     "shell.execute_reply.started": "2024-04-18T18:38:59.597759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_text.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_text.py\n",
    "\n",
    "#========================== util: text\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from pypdf import PdfWriter\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# local imports\n",
    "from src.util_ocr import get_ocr_lst_text_from_uploaded_file\n",
    "\n",
    "# import pytesseract\n",
    "import pytesseract\n",
    "pytesseract.tesseract_cmd = r\"C:\\Users\\a126291\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Single PDF No OCR\n",
    "def get_lst_text_from_single_pdf_no_ocr(path_pdf):\n",
    "    r'Get list of text for each pages of pdf document'\n",
    "    from PyPDF2 import PdfReader\n",
    "\n",
    "    pdf_reader = PdfReader(path_pdf)\n",
    "    lst_text = []\n",
    "    for page in pdf_reader.pages:\n",
    "        text = page.extract_text()\n",
    "        lst_text.append(text)\n",
    "    return lst_text\n",
    "\n",
    "\n",
    "def get_lst_text_from_uploaded_file(uploaded_file,ocr=False,pytesseract_path=None):\n",
    "    r'''Get list of text from a single pdf (works for both ocr and non-ocr pdf).\n",
    "\n",
    "    '''\n",
    "    lst_text = []\n",
    "    if ocr:\n",
    "        lst_text = get_ocr_lst_text_from_uploaded_file(uploaded_file, language='eng',pytesseract_path=None)\n",
    "    else:\n",
    "        lst_text = get_lst_text_from_single_pdf_no_ocr(uploaded_file)\n",
    "    return lst_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72a5b330-e5f8-481d-bca8-4b4fa12dbddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:59.605161Z",
     "iopub.status.busy": "2024-04-18T18:38:59.605161Z",
     "iopub.status.idle": "2024-04-18T18:38:59.607625Z",
     "shell.execute_reply": "2024-04-18T18:38:59.607625Z",
     "shell.execute_reply.started": "2024-04-18T18:38:59.605161Z"
    }
   },
   "outputs": [],
   "source": [
    "# !explorer.exe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b2ee742-d7f8-42b0-aef1-014484406c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:38:59.609392Z",
     "iopub.status.busy": "2024-04-18T18:38:59.608376Z",
     "iopub.status.idle": "2024-04-18T18:39:07.944420Z",
     "shell.execute_reply": "2024-04-18T18:39:07.944420Z",
     "shell.execute_reply.started": "2024-04-18T18:38:59.609392Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.util_text import get_lst_text_from_uploaded_file\n",
    "uploaded_file = path_pdf_ocr\n",
    "lst_text = get_lst_text_from_uploaded_file(uploaded_file,ocr=True,pytesseract_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2698ce29-ac9b-423d-8db7-2f79f0415f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:39:07.944420Z",
     "iopub.status.busy": "2024-04-18T18:39:07.944420Z",
     "iopub.status.idle": "2024-04-18T18:39:07.952886Z",
     "shell.execute_reply": "2024-04-18T18:39:07.952886Z",
     "shell.execute_reply.started": "2024-04-18T18:39:07.944420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f724157-a823-4356-9675-7d2d72297531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:39:07.953807Z",
     "iopub.status.busy": "2024-04-18T18:39:07.953807Z",
     "iopub.status.idle": "2024-04-18T18:39:07.965829Z",
     "shell.execute_reply": "2024-04-18T18:39:07.965829Z",
     "shell.execute_reply.started": "2024-04-18T18:39:07.953807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y DOSAGE AND ADMINISTRATION\n",
      "\n",
      "21 Important Injection Instructions\n",
      "\n",
      "For ophthalmic intravitreal injection. EYLEA must only be admumstered by a qualified\n",
      "physician.\n",
      "\n",
      "2.2 — Neovascular (Wet) Age-Related Macular Degeneration (AMD)\n",
      "\n",
      "The recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\n",
      "intravitreal injection every 4 weeks (monthly) for the first 12 weeks (3 months), followed by\n",
      "\n",
      "2 me (0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may\n",
      "be dosed as frequently as 2 me every 4 weeks (monthly), additional efficacy was not\n",
      "demonstrated in most patients when EYLEA was dosed every 4 weeks compared to every\n",
      "\n",
      "8 weeks [see Clinical Studies (14.1)]. Some patients may need every 4 week (monthly) dosing\n",
      "after the first 12 weeks (3 months).\n",
      "\n",
      "13 Macular Edema Following Retinal Vein Occlusion (RVO)\n",
      "\n",
      "The recommended dose for EYLEA 1s 2 mg (0.05 ml or 50 microliters) admumstered by\n",
      "intravitreal injection once every 4 weeks (monthly) [see Clinical Studies (24.2), (14.3)}\n",
      "\n",
      "24 Diabetic Macular Edema (DME)\n",
      "\n",
      "The recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\n",
      "intravitreal injection every 4 weeks (monthly) for the frst 5 imjections, followed by 2 mg\n",
      "\n",
      "(0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may be\n",
      "dosed as frequently as 2 mg every 4 weeks (monthly), additional efficacy was not demonstrated\n",
      "10 most patients when EYLEA was dosed every 4 weeks compared to every 8 weeks [see\n",
      "Clinical Studies (14.4)]. Some patients may need every 4 week (monthly) dosing after the firs\n",
      "20 weeks (5 months).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if lst_text:\n",
    "    print(lst_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981ebfd-8a41-481c-9fa6-72fe32dff9f6",
   "metadata": {},
   "source": [
    "# Util: doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee15fe78-76be-4bd4-ba6d-5adabfc41df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:39:07.965829Z",
     "iopub.status.busy": "2024-04-18T18:39:07.965829Z",
     "iopub.status.idle": "2024-04-18T18:39:07.978679Z",
     "shell.execute_reply": "2024-04-18T18:39:07.978679Z",
     "shell.execute_reply.started": "2024-04-18T18:39:07.965829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_doc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_doc.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "# local imports\n",
    "from src.util_text import get_lst_text_from_uploaded_file\n",
    "\n",
    "def get_doc_chunks_from_lst_text(lst_text,path_pdf):\n",
    "    \"\"\"Convert list of text to list of langchain Documents.\n",
    "\n",
    "    Note: we have chunks, not the page documents\n",
    "\n",
    "    from langchain.docstore.document import Document\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \"\"\"\n",
    "    from langchain.docstore.document import Document\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from pathlib import Path\n",
    "\n",
    "    if isinstance(lst_text, str):\n",
    "        # Take a single string as one page\n",
    "        lst_text = [lst_text]\n",
    "\n",
    "    # get docs\n",
    "    page_docs = [Document(page_content=page) for page in lst_text]\n",
    "\n",
    "    # Add page numbers as metadata\n",
    "    for i, doc in enumerate(page_docs):\n",
    "        doc.metadata[\"page\"] = i + 1\n",
    "\n",
    "    # Split pages into chunks\n",
    "    doc_chunks = []\n",
    "\n",
    "    for doc in page_docs:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
    "            )\n",
    "            # Add sources a metadata\n",
    "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
    "            doc.metadata[\"path_name\"] = Path(path_pdf).name\n",
    "            doc.metadata[\"path_name_full\"] = str(path_pdf)\n",
    "            doc_chunks.append(doc)\n",
    "    return doc_chunks\n",
    "\n",
    "def get_all_doc_chunks_from_path_pdfs(path_pdfs,ocr=False):\n",
    "    r'''Get document chunks for all the pdfs.\n",
    "\n",
    "    Depends:\n",
    "    ========\n",
    "    - get_lst_text_from_uploaded_file\n",
    "    - get_doc_chunks_from_lst_text\n",
    "\n",
    "    '''\n",
    "    all_doc_chunks = []\n",
    "    for i, path_pdf in enumerate(path_pdfs):\n",
    "        lst_text =  get_lst_text_from_uploaded_file(path_pdf,ocr=ocr)\n",
    "        doc_chunks = get_doc_chunks_from_lst_text(lst_text,path_pdf)\n",
    "        for doc in doc_chunks:\n",
    "            doc.metadata[\"pdf_number\"] = str(i+1)\n",
    "            all_doc_chunks.append(doc)\n",
    "    return all_doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91dc5648-4b65-418e-9e58-40fcf59ceb93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:39:07.978679Z",
     "iopub.status.busy": "2024-04-18T18:39:07.978679Z",
     "iopub.status.idle": "2024-04-18T18:39:16.444041Z",
     "shell.execute_reply": "2024-04-18T18:39:16.444041Z",
     "shell.execute_reply.started": "2024-04-18T18:39:07.978679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.util_doc import get_all_doc_chunks_from_path_pdfs\n",
    "\n",
    "path_pdfs = [path_pdf_ocr]\n",
    "\n",
    "all_doc_chunks = get_all_doc_chunks_from_path_pdfs(path_pdfs,ocr=True)\n",
    "doc_chunk = all_doc_chunks[0]\n",
    "\n",
    "type(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eebfb03-6746-4756-b69b-5befa0cdec73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T18:39:16.444723Z",
     "iopub.status.busy": "2024-04-18T18:39:16.444723Z",
     "iopub.status.idle": "2024-04-18T18:39:16.447787Z",
     "shell.execute_reply": "2024-04-18T18:39:16.447787Z",
     "shell.execute_reply.started": "2024-04-18T18:39:16.444723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='y DOSAGE AND ADMINISTRATION\\n\\n21 Important Injection Instructions\\n\\nFor ophthalmic intravitreal injection. EYLEA must only be admumstered by a qualified\\nphysician.\\n\\n2.2 — Neovascular (Wet) Age-Related Macular Degeneration (AMD)\\n\\nThe recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\\nintravitreal injection every 4 weeks (monthly) for the first 12 weeks (3 months), followed by\\n\\n2 me (0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may\\nbe dosed as frequently as 2 me every 4 weeks (monthly), additional efficacy was not\\ndemonstrated in most patients when EYLEA was dosed every 4 weeks compared to every\\n\\n8 weeks [see Clinical Studies (14.1)]. Some patients may need every 4 week (monthly) dosing\\nafter the first 12 weeks (3 months).\\n\\n13 Macular Edema Following Retinal Vein Occlusion (RVO)\\n\\nThe recommended dose for EYLEA 1s 2 mg (0.05 ml or 50 microliters) admumstered by\\nintravitreal injection once every 4 weeks (monthly) [see Clinical Studies (24.2), (14.3)}\\n\\n24 Diabetic Macular Edema (DME)\\n\\nThe recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\\nintravitreal injection every 4 weeks (monthly) for the frst 5 imjections, followed by 2 mg\\n\\n(0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may be\\ndosed as frequently as 2 mg every 4 weeks (monthly), additional efficacy was not demonstrated\\n10 most patients when EYLEA was dosed every 4 weeks compared to every 8 weeks [see\\nClinical Studies (14.4)]. Some patients may need every 4 week (monthly) dosing after the firs\\n20 weeks (5 months).', metadata={'page': 1, 'chunk': 0, 'source': '1-0', 'path_name': 'screenshot_pages_eylea.pdf', 'path_name_full': 'C:\\\\Users\\\\a126291\\\\OneDrive - AmerisourceBergen(ABC)\\\\data\\\\pdf_files\\\\ocr_pdf\\\\screenshot_pages_eylea.pdf', 'pdf_number': '1'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cc94e-f0e0-4834-b99b-b1ce4a37e708",
   "metadata": {},
   "source": [
    "# Util: LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aeb112-b2ff-4016-9f7d-ff93735e0289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8daa8805-0de9-410e-a18c-6ba22897574b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T21:03:25.270889Z",
     "iopub.status.busy": "2024-04-18T21:03:25.270889Z",
     "iopub.status.idle": "2024-04-18T21:03:33.311370Z",
     "shell.execute_reply": "2024-04-18T21:03:33.311370Z",
     "shell.execute_reply.started": "2024-04-18T21:03:25.270889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\embeddings\\azure_openai.py:113: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://qa.gai.cencora.com/aoai to https://qa.gai.cencora.com/aoai/openai.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.azure_openai.AzureChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://qa.gai.cencora.com/aoai to https://qa.gai.cencora.com/aoai/openai.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://qa.gai.cencora.com/aoai to https://qa.gai.cencora.com/aoai/openai.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AzureChatOpenAI\n__root__\n  base_url and azure_endpoint are mutually exclusive (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14064\\1310684988.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m llm = AzureChatOpenAI(\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mopenai_api_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"azure\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mopenai_api_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopenai_api_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
      "\u001b[1;32m~\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
      "\u001b[1;32m~\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\load\\serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\venv\\py311_camelot\\Lib\\site-packages\\pydantic\\v1\\main.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__dict__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for AzureChatOpenAI\n__root__\n  base_url and azure_endpoint are mutually exclusive (type=value_error)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Variables\n",
    "path_pdf = r\"C:\\Users\\a126291\\OneDrive - AmerisourceBergen(ABC)\\data\\pdf_files\\cencora_earning_reports\\AmerisourceBergen-Reports-Fiscal-2023-Second-Quarter-Results-2023.pdf\"\n",
    "\n",
    "embed_model= \"text-embedding-ada-002\"\n",
    "vectore_store_persist_directory = 'vector_store'\n",
    "\n",
    "# Config\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser(\"~/.utils\"))\n",
    "from util_openai import get_config_dict\n",
    "config = get_config_dict(env=None)\n",
    "\n",
    "# openai_api_key=\"242ad9b0c6d84b5fb4307061d5f05a86\"\n",
    "# openai_api_version=\"2023-03-15-preview\"\n",
    "\n",
    "# openai_api_base=\"https://cencoragaidev-bhakadc4hreqbthb.z01.azurefd.net/gpsdatascience_dev\"\n",
    "# azure_endpoint=\"https://cencoragaidev-bhakadc4hreqbthb.z01.azurefd.net/gpsdatascience_dev\"\n",
    "deployment_name='gpt-35-turbo-16k'\n",
    "\n",
    "openai_api_key = config[\"openai_api_key\"]\n",
    "openai_api_version = config[\"openai_api_version\"]\n",
    "\n",
    "openai_api_base = config[\"openai_api_base\"]\n",
    "azure_endpoint = config[\"azure_endpoint\"]\n",
    "# deployment_name = config[\"deployment_name\"]\n",
    "\n",
    "# Load pdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(path_pdf)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split Documents Into Chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# embedding\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    chunk_size=1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "# vector store\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "vector_store = FAISS.from_documents(documents=pages, embedding=embeddings)\n",
    "vector_store.save_local(vectore_store_persist_directory)\n",
    "\n",
    "# llm\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    deployment_name=deployment_name,\n",
    "    model_name=\"text-davinci-002\",\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=openai_api_version,\n",
    "    temperature=0\n",
    "    )\n",
    "\n",
    "# Get vector store from local file\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.load_local(vectore_store_persist_directory, embeddings, allow_dangerous_deserialization=True,)\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":2},\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# Create RetrivalQA Chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever = retriever\n",
    ")\n",
    "\n",
    "# Create Query And Get Response\n",
    "query = 'What are the year to year gain in revenue?'\n",
    "result = qa.invoke({'query': query})\n",
    "print(result['result'])\n",
    "print('='*100)\n",
    "\n",
    "## Using: ConversationalRetrievalChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm,retriever)\n",
    "chat_history = []\n",
    "query = \"Is there gain or loss of revenue in this quarter?\"\n",
    "\n",
    "result = qa.invoke({'question': query, 'chat_history': chat_history})\n",
    "print(result['answer'])\n",
    "print('='*100)\n",
    "chat_history = [(query,result['answer'])]\n",
    "query = \"Is there gain in revenue for U.S. Healthcare Solutions this quarter?\"\n",
    "\n",
    "result = qa.invoke({'question': query, 'chat_history': chat_history})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fb3aa-5471-451e-be3b-c37a319f64f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
