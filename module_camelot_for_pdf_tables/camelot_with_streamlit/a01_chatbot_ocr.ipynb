{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f27a189-1e64-4957-918b-411ec3e05c2a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a465f2fc-0119-41a8-8c42-77e6043f0f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:05.338852Z",
     "iopub.status.busy": "2024-04-18T19:57:05.338852Z",
     "iopub.status.idle": "2024-04-18T19:57:05.346777Z",
     "shell.execute_reply": "2024-04-18T19:57:05.346777Z",
     "shell.execute_reply.started": "2024-04-18T19:57:05.338852Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time_start_notebook = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd333e36-2a05-423e-8895-b22079e893aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:05.348784Z",
     "iopub.status.busy": "2024-04-18T19:57:05.346777Z",
     "iopub.status.idle": "2024-04-18T19:57:07.823132Z",
     "shell.execute_reply": "2024-04-18T19:57:07.823132Z",
     "shell.execute_reply.started": "2024-04-18T19:57:05.346777Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import pypdf\n",
    "from PyPDF2 import PdfReader\n",
    "from pypdf import PdfWriter\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import streamlit\n",
    "import streamlit as st\n",
    "import base64\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import openai\n",
    "import langchain\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "#--- ocr\n",
    "import pdf2image\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c92443-bcab-48eb-8958-e5563f98f815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.823132Z",
     "iopub.status.busy": "2024-04-18T19:57:07.823132Z",
     "iopub.status.idle": "2024-04-18T19:57:07.850741Z",
     "shell.execute_reply": "2024-04-18T19:57:07.850741Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.823132Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06964bec-25e9-4673-91f7-006419f3dc32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.850741Z",
     "iopub.status.busy": "2024-04-18T19:57:07.850741Z",
     "iopub.status.idle": "2024-04-18T19:57:07.918935Z",
     "shell.execute_reply": "2024-04-18T19:57:07.918935Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.850741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain  : 0.1.16\n",
      "streamlit  : 1.33.0\n",
      "pandas     : 1.5.3\n",
      "numpy      : 1.26.4\n",
      "pytesseract: 0.3.10\n",
      "pypdf      : 4.2.0\n",
      "openai     : 1.22.0\n",
      "sys        : 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]\n",
      "pdf2image  : 1.17.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec0c90-8251-4477-b107-7ed8ee81c7c1",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53d7c98-24d5-4ffe-aba5-8d47805ee999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.920119Z",
     "iopub.status.busy": "2024-04-18T19:57:07.919940Z",
     "iopub.status.idle": "2024-04-18T19:57:07.922164Z",
     "shell.execute_reply": "2024-04-18T19:57:07.922164Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.920119Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path_pdf_ocr = r\"C:\\Users\\a126291\\OneDrive - AmerisourceBergen(ABC)\\data\\pdf_files\\ocr_pdf\\screenshot_pages_eylea.pdf\"\n",
    "path_pdf_non_ocr = r\"C:\\Users\\a126291\\OneDrive - AmerisourceBergen(ABC)\\data\\pdf_files\\fda_drugs\\fda_eylea.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40084d-1c7a-4ce7-b7f2-01d9b417fb10",
   "metadata": {},
   "source": [
    "# source directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f969aec-c2ff-439c-9ece-18ccf1a6e339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.924171Z",
     "iopub.status.busy": "2024-04-18T19:57:07.923173Z",
     "iopub.status.idle": "2024-04-18T19:57:07.939308Z",
     "shell.execute_reply": "2024-04-18T19:57:07.939308Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.924171Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.isdir('src'):\n",
    "    shutil.rmtree('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f97200-0abc-49b9-a6a6-e17573cec265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.939308Z",
     "iopub.status.busy": "2024-04-18T19:57:07.939308Z",
     "iopub.status.idle": "2024-04-18T19:57:07.943653Z",
     "shell.execute_reply": "2024-04-18T19:57:07.943653Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.939308Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('src'):\n",
    "    os.makedirs('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ba5ec0-61ac-483e-a81c-4e2af996591d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.944664Z",
     "iopub.status.busy": "2024-04-18T19:57:07.944664Z",
     "iopub.status.idle": "2024-04-18T19:57:07.951314Z",
     "shell.execute_reply": "2024-04-18T19:57:07.951314Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.944664Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('src/__init__.py','w') as fh:\n",
    "    fh.write('# Author: Bhishan Poudel\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64298e81-11f8-4b56-a6ed-5238c4c27248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:07.952780Z",
     "iopub.status.busy": "2024-04-18T19:57:07.952780Z",
     "iopub.status.idle": "2024-04-18T19:57:08.708371Z",
     "shell.execute_reply": "2024-04-18T19:57:08.708371Z",
     "shell.execute_reply.started": "2024-04-18T19:57:07.952780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "!ls src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5a486d-cb06-428e-a898-d7fa98373648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:08.708371Z",
     "iopub.status.busy": "2024-04-18T19:57:08.708371Z",
     "iopub.status.idle": "2024-04-18T19:57:09.093573Z",
     "shell.execute_reply": "2024-04-18T19:57:09.093573Z",
     "shell.execute_reply.started": "2024-04-18T19:57:08.708371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Author: Bhishan Poudel\n"
     ]
    }
   ],
   "source": [
    "!cat src/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffa1a2-a568-405e-babe-60b8ff2e59e1",
   "metadata": {},
   "source": [
    "# util: config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eda512f-9bc4-4d35-b17e-f4757af57f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:09.094929Z",
     "iopub.status.busy": "2024-04-18T19:57:09.093573Z",
     "iopub.status.idle": "2024-04-18T19:57:09.101482Z",
     "shell.execute_reply": "2024-04-18T19:57:09.100806Z",
     "shell.execute_reply.started": "2024-04-18T19:57:09.094929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/config.py\n",
    "\n",
    "def get_config():\n",
    "    # config\n",
    "    openai_api_key = \"f4001c4b49a845309d386e9014b7ae6b\"\n",
    "    openai_api_base = \"https://qa.gai.cencora.com/aoai\"\n",
    "    azure_endpoint = openai_api_base\n",
    "    openai_api_version = \"2023-03-15-preview\"\n",
    "    openai_api_type = \"azure\"\n",
    "\n",
    "    openai_deployment_name = \"gpt-35-turbo-16k\"\n",
    "    openai_model_name      = \"gpt-35-turbo-16k\"\n",
    "\n",
    "    # os environments\n",
    "    import os\n",
    "    os.environ['OPENAI_API_TYPE'] = openai_api_type\n",
    "    os.environ['OPENAI_API_VERSION'] = openai_api_version\n",
    "    os.environ['OPENAI_API_BASE'] = openai_api_base\n",
    "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "    # openai environments\n",
    "    import openai\n",
    "    openai.api_key = openai_api_key\n",
    "    openai.api_type = openai_api_type\n",
    "    openai.api_base = openai_api_base\n",
    "    openai.api_version = openai_api_version\n",
    "    openai.api_key = openai_api_key\n",
    "\n",
    "    config = {\n",
    "    'openai_api_base': openai_api_base,\n",
    "    'openai_api_version': openai_api_version,\n",
    "    'deployment_name': openai_deployment_name,\n",
    "    'model_name': openai_model_name,\n",
    "    'openai_api_key': openai_api_key,\n",
    "    'openai_api_type': openai_api_type\n",
    "    }\n",
    "\n",
    "    return config\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e2523d-0200-4db2-affe-3dec358b8b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:09.101482Z",
     "iopub.status.busy": "2024-04-18T19:57:09.101482Z",
     "iopub.status.idle": "2024-04-18T19:57:09.128623Z",
     "shell.execute_reply": "2024-04-18T19:57:09.128130Z",
     "shell.execute_reply.started": "2024-04-18T19:57:09.101482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-35-turbo-16k'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import config\n",
    "\n",
    "config['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891c24a-b7cf-4762-9036-e066bd254d56",
   "metadata": {},
   "source": [
    "# Util: ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "900fab76-b66a-4185-883b-4a4ed790747c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:09.129710Z",
     "iopub.status.busy": "2024-04-18T19:57:09.129710Z",
     "iopub.status.idle": "2024-04-18T19:57:09.136532Z",
     "shell.execute_reply": "2024-04-18T19:57:09.136033Z",
     "shell.execute_reply.started": "2024-04-18T19:57:09.129710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_ocr.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_ocr.py\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "#--- ocr\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "pytesseract.tesseract_cmd = r\"C:\\Users\\a126291\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "#@st.cache_data\n",
    "def get_ocr_lst_text_from_uploaded_file(uploaded_file, language='eng',pytesseract_path=None):\n",
    "    import pdf2image\n",
    "    import pytesseract\n",
    "    from pathlib import Path\n",
    "\n",
    "    if pytesseract_path == None:\n",
    "        pytesseract_path = r\"C:\\Users\\a126291\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "    pytesseract.tesseract_cmd = pytesseract_path\n",
    "\n",
    "    try: # streamlit uploded file\n",
    "        data_bytes = uploaded_file.getvalue()\n",
    "    except:\n",
    "        try: # regular file path\n",
    "            path_pdf = Path(uploaded_file)\n",
    "            if path_pdf.exists():\n",
    "                with open(path_pdf, 'rb') as file:\n",
    "                    data_bytes = file.read()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    pil_images = pdf2image.convert_from_bytes(data_bytes)\n",
    "    lst_txt = []\n",
    "    for pil_image in pil_images:\n",
    "        text_one_page = pytesseract.image_to_string(pil_image, lang=language)\n",
    "        lst_txt.append(text_one_page)\n",
    "    return lst_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d25337-5793-4cfd-a24f-740eb9e99bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:09.137721Z",
     "iopub.status.busy": "2024-04-18T19:57:09.137721Z",
     "iopub.status.idle": "2024-04-18T19:57:18.962826Z",
     "shell.execute_reply": "2024-04-18T19:57:18.962826Z",
     "shell.execute_reply.started": "2024-04-18T19:57:09.137721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croliters) admuistered by\n",
      "intravitreal injection every 4 weeks (monthly) for the frst 5 imjections, followed by 2 mg\n",
      "\n",
      "(0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may be\n",
      "dosed as frequently as 2 mg every 4 weeks (monthly), additional efficacy was not demonstrated\n",
      "10 most patients when EYLEA was dosed every 4 weeks compared to every 8 weeks [see\n",
      "Clinical Studies (14.4)]. Some patients may need every 4 week (monthly) dosing after the firs\n",
      "20 weeks (5 months).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.util_ocr import get_ocr_lst_text_from_uploaded_file\n",
    "\n",
    "path_pdf = path_pdf_ocr\n",
    "lst_text = get_ocr_lst_text_from_uploaded_file(uploaded_file=path_pdf, language='eng',pytesseract_path=None)\n",
    "\n",
    "print(lst_text[0][-500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1137d3b-1e7f-4efe-9355-77cb4e6445c2",
   "metadata": {},
   "source": [
    "# Util: Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca2ef8e2-4c34-4120-ae30-f748d5092e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:18.963748Z",
     "iopub.status.busy": "2024-04-18T19:57:18.963748Z",
     "iopub.status.idle": "2024-04-18T19:57:18.975905Z",
     "shell.execute_reply": "2024-04-18T19:57:18.975905Z",
     "shell.execute_reply.started": "2024-04-18T19:57:18.963748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_text.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_text.py\n",
    "\n",
    "#========================== util: text\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from pypdf import PdfWriter\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# local imports\n",
    "from src.util_ocr import get_ocr_lst_text_from_uploaded_file\n",
    "\n",
    "# import pytesseract\n",
    "import pytesseract\n",
    "pytesseract.tesseract_cmd = r\"C:\\Users\\a126291\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Single PDF No OCR\n",
    "def get_lst_text_from_single_pdf_no_ocr(path_pdf):\n",
    "    r'Get list of text for each pages of pdf document'\n",
    "    from PyPDF2 import PdfReader\n",
    "\n",
    "    pdf_reader = PdfReader(path_pdf)\n",
    "    lst_text = []\n",
    "    for page in pdf_reader.pages:\n",
    "        text = page.extract_text()\n",
    "        lst_text.append(text)\n",
    "    return lst_text\n",
    "\n",
    "\n",
    "def get_lst_text_from_uploaded_file(uploaded_file,ocr=False,pytesseract_path=None):\n",
    "    r'''Get list of text from a single pdf (works for both ocr and non-ocr pdf).\n",
    "\n",
    "    '''\n",
    "    lst_text = []\n",
    "    if ocr:\n",
    "        lst_text = get_ocr_lst_text_from_uploaded_file(uploaded_file, language='eng',pytesseract_path=None)\n",
    "    else:\n",
    "        lst_text = get_lst_text_from_single_pdf_no_ocr(uploaded_file)\n",
    "    return lst_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72a5b330-e5f8-481d-bca8-4b4fa12dbddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:18.975905Z",
     "iopub.status.busy": "2024-04-18T19:57:18.975905Z",
     "iopub.status.idle": "2024-04-18T19:57:18.980820Z",
     "shell.execute_reply": "2024-04-18T19:57:18.980231Z",
     "shell.execute_reply.started": "2024-04-18T19:57:18.975905Z"
    }
   },
   "outputs": [],
   "source": [
    "# !explorer.exe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b2ee742-d7f8-42b0-aef1-014484406c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:18.981198Z",
     "iopub.status.busy": "2024-04-18T19:57:18.981198Z",
     "iopub.status.idle": "2024-04-18T19:57:27.377866Z",
     "shell.execute_reply": "2024-04-18T19:57:27.377866Z",
     "shell.execute_reply.started": "2024-04-18T19:57:18.981198Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.util_text import get_lst_text_from_uploaded_file\n",
    "uploaded_file = path_pdf_ocr\n",
    "lst_text = get_lst_text_from_uploaded_file(uploaded_file,ocr=True,pytesseract_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2698ce29-ac9b-423d-8db7-2f79f0415f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:27.377866Z",
     "iopub.status.busy": "2024-04-18T19:57:27.377866Z",
     "iopub.status.idle": "2024-04-18T19:57:27.388116Z",
     "shell.execute_reply": "2024-04-18T19:57:27.387923Z",
     "shell.execute_reply.started": "2024-04-18T19:57:27.377866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f724157-a823-4356-9675-7d2d72297531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:27.389264Z",
     "iopub.status.busy": "2024-04-18T19:57:27.389264Z",
     "iopub.status.idle": "2024-04-18T19:57:27.394276Z",
     "shell.execute_reply": "2024-04-18T19:57:27.394276Z",
     "shell.execute_reply.started": "2024-04-18T19:57:27.389264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y DOSAGE AND ADMINISTRATION\n",
      "\n",
      "21 Important Injection Instructions\n",
      "\n",
      "For ophthalmic intravitreal injection. EYLEA must only be admumstered by a qualified\n",
      "physician.\n",
      "\n",
      "2.2 — Neovascular (Wet) Age-Related Macular Degeneration (AMD)\n",
      "\n",
      "The recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\n",
      "intravitreal injection every 4 weeks (monthly) for the first 12 weeks (3 months), followed by\n",
      "\n",
      "2 me (0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may\n",
      "be dosed as frequently as 2 me every 4 weeks (monthly), additional efficacy was not\n",
      "demonstrated in most patients when EYLEA was dosed every 4 weeks compared to every\n",
      "\n",
      "8 weeks [see Clinical Studies (14.1)]. Some patients may need every 4 week (monthly) dosing\n",
      "after the first 12 weeks (3 months).\n",
      "\n",
      "13 Macular Edema Following Retinal Vein Occlusion (RVO)\n",
      "\n",
      "The recommended dose for EYLEA 1s 2 mg (0.05 ml or 50 microliters) admumstered by\n",
      "intravitreal injection once every 4 weeks (monthly) [see Clinical Studies (24.2), (14.3)}\n",
      "\n",
      "24 Diabetic Macular Edema (DME)\n",
      "\n",
      "The recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\n",
      "intravitreal injection every 4 weeks (monthly) for the frst 5 imjections, followed by 2 mg\n",
      "\n",
      "(0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may be\n",
      "dosed as frequently as 2 mg every 4 weeks (monthly), additional efficacy was not demonstrated\n",
      "10 most patients when EYLEA was dosed every 4 weeks compared to every 8 weeks [see\n",
      "Clinical Studies (14.4)]. Some patients may need every 4 week (monthly) dosing after the firs\n",
      "20 weeks (5 months).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if lst_text:\n",
    "    print(lst_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981ebfd-8a41-481c-9fa6-72fe32dff9f6",
   "metadata": {},
   "source": [
    "# Util: doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee15fe78-76be-4bd4-ba6d-5adabfc41df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:27.395276Z",
     "iopub.status.busy": "2024-04-18T19:57:27.394276Z",
     "iopub.status.idle": "2024-04-18T19:57:27.400610Z",
     "shell.execute_reply": "2024-04-18T19:57:27.400610Z",
     "shell.execute_reply.started": "2024-04-18T19:57:27.395276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_doc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_doc.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "# local imports\n",
    "from src.util_text import get_lst_text_from_uploaded_file\n",
    "\n",
    "def get_doc_chunks_from_lst_text(lst_text,path_pdf):\n",
    "    \"\"\"Convert list of text to list of langchain Documents.\n",
    "\n",
    "    Note: we have chunks, not the page documents\n",
    "\n",
    "    from langchain.docstore.document import Document\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \"\"\"\n",
    "    from langchain.docstore.document import Document\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from pathlib import Path\n",
    "\n",
    "    if isinstance(lst_text, str):\n",
    "        # Take a single string as one page\n",
    "        lst_text = [lst_text]\n",
    "\n",
    "    # get docs\n",
    "    page_docs = [Document(page_content=page) for page in lst_text]\n",
    "\n",
    "    # Add page numbers as metadata\n",
    "    for i, doc in enumerate(page_docs):\n",
    "        doc.metadata[\"page\"] = i + 1\n",
    "\n",
    "    # Split pages into chunks\n",
    "    doc_chunks = []\n",
    "\n",
    "    for doc in page_docs:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
    "            )\n",
    "            # Add sources a metadata\n",
    "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
    "            doc.metadata[\"path_name\"] = Path(path_pdf).name\n",
    "            doc.metadata[\"path_name_full\"] = str(path_pdf)\n",
    "            doc_chunks.append(doc)\n",
    "    return doc_chunks\n",
    "\n",
    "def get_all_doc_chunks_from_path_pdfs(path_pdfs,ocr=False):\n",
    "    r'''Get document chunks for all the pdfs.\n",
    "\n",
    "    Depends:\n",
    "    ========\n",
    "    - get_lst_text_from_uploaded_file\n",
    "    - get_doc_chunks_from_lst_text\n",
    "\n",
    "    '''\n",
    "    all_doc_chunks = []\n",
    "    for i, path_pdf in enumerate(path_pdfs):\n",
    "        lst_text =  get_lst_text_from_uploaded_file(path_pdf,ocr=ocr)\n",
    "        doc_chunks = get_doc_chunks_from_lst_text(lst_text,path_pdf)\n",
    "        for doc in doc_chunks:\n",
    "            doc.metadata[\"pdf_number\"] = str(i+1)\n",
    "            all_doc_chunks.append(doc)\n",
    "    return all_doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91dc5648-4b65-418e-9e58-40fcf59ceb93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:27.404793Z",
     "iopub.status.busy": "2024-04-18T19:57:27.404162Z",
     "iopub.status.idle": "2024-04-18T19:57:35.881849Z",
     "shell.execute_reply": "2024-04-18T19:57:35.881849Z",
     "shell.execute_reply.started": "2024-04-18T19:57:27.404793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.util_doc import get_all_doc_chunks_from_path_pdfs\n",
    "\n",
    "path_pdfs = [path_pdf_ocr]\n",
    "\n",
    "all_doc_chunks = get_all_doc_chunks_from_path_pdfs(path_pdfs,ocr=True)\n",
    "doc_chunk = all_doc_chunks[0]\n",
    "\n",
    "type(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eebfb03-6746-4756-b69b-5befa0cdec73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:35.882510Z",
     "iopub.status.busy": "2024-04-18T19:57:35.882510Z",
     "iopub.status.idle": "2024-04-18T19:57:35.885664Z",
     "shell.execute_reply": "2024-04-18T19:57:35.885664Z",
     "shell.execute_reply.started": "2024-04-18T19:57:35.882510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='y DOSAGE AND ADMINISTRATION\\n\\n21 Important Injection Instructions\\n\\nFor ophthalmic intravitreal injection. EYLEA must only be admumstered by a qualified\\nphysician.\\n\\n2.2 — Neovascular (Wet) Age-Related Macular Degeneration (AMD)\\n\\nThe recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\\nintravitreal injection every 4 weeks (monthly) for the first 12 weeks (3 months), followed by\\n\\n2 me (0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may\\nbe dosed as frequently as 2 me every 4 weeks (monthly), additional efficacy was not\\ndemonstrated in most patients when EYLEA was dosed every 4 weeks compared to every\\n\\n8 weeks [see Clinical Studies (14.1)]. Some patients may need every 4 week (monthly) dosing\\nafter the first 12 weeks (3 months).\\n\\n13 Macular Edema Following Retinal Vein Occlusion (RVO)\\n\\nThe recommended dose for EYLEA 1s 2 mg (0.05 ml or 50 microliters) admumstered by\\nintravitreal injection once every 4 weeks (monthly) [see Clinical Studies (24.2), (14.3)}\\n\\n24 Diabetic Macular Edema (DME)\\n\\nThe recommended dose for EYLEA 1s 2 me (0.05 mL or 50 microliters) admuistered by\\nintravitreal injection every 4 weeks (monthly) for the frst 5 imjections, followed by 2 mg\\n\\n(0.05 mL) via intravitreal injection once every 8 weeks (2 months). Although EYLEA may be\\ndosed as frequently as 2 mg every 4 weeks (monthly), additional efficacy was not demonstrated\\n10 most patients when EYLEA was dosed every 4 weeks compared to every 8 weeks [see\\nClinical Studies (14.4)]. Some patients may need every 4 week (monthly) dosing after the firs\\n20 weeks (5 months).', metadata={'page': 1, 'chunk': 0, 'source': '1-0', 'path_name': 'screenshot_pages_eylea.pdf', 'path_name_full': 'C:\\\\Users\\\\a126291\\\\OneDrive - AmerisourceBergen(ABC)\\\\data\\\\pdf_files\\\\ocr_pdf\\\\screenshot_pages_eylea.pdf', 'pdf_number': '1'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cc94e-f0e0-4834-b99b-b1ce4a37e708",
   "metadata": {},
   "source": [
    "# Util: LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e4c0b0-974b-44c2-bea8-338d8c28497c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:35.886664Z",
     "iopub.status.busy": "2024-04-18T19:57:35.886384Z",
     "iopub.status.idle": "2024-04-18T19:57:35.901876Z",
     "shell.execute_reply": "2024-04-18T19:57:35.901215Z",
     "shell.execute_reply.started": "2024-04-18T19:57:35.886664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_llm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_llm.py\n",
    "from langchain.embeddings import OpenAIEmbeddings,AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "#======================= llm functions\n",
    "def get_vectorstore_from_doc_chunks(doc_chunks):\n",
    "    # new versions of openai needs AzureOpenAIEmbeddings\n",
    "    embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1)\n",
    "    # embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1)\n",
    "    vectorstore = FAISS.from_documents(documents=doc_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def get_conversation_chain(vectorstore, temp, config):\n",
    "    # llm\n",
    "    llm = AzureChatOpenAI(\n",
    "        openai_api_base=config['openai_api_base'],\n",
    "        openai_api_version=config['openai_api_version'],\n",
    "        deployment_name=config['deployment_name'],\n",
    "        model_name=config['model_name'],\n",
    "        openai_api_key=config['openai_api_key'],\n",
    "        openai_api_type=config['openai_api_type'],\n",
    "        temperature=temp)\n",
    "\n",
    "    # memory\n",
    "    memory = ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\",\n",
    "                input_key='question',\n",
    "                output_key='answer',\n",
    "                return_messages=True)\n",
    "\n",
    "    # conversation chain\n",
    "    conv_chain = ConversationalRetrievalChain.from_llm(\n",
    "                llm=llm,\n",
    "                retriever=vectorstore.as_retriever(),\n",
    "                memory=memory,\n",
    "                return_source_documents=True,\n",
    "                return_generated_question=True,\n",
    "                #combine_docs_chain_kwargs={\"prompt\": chat_prompt_template}\n",
    "        )\n",
    "\n",
    "    return conv_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e86823b1-f6cd-4a68-8462-6c91f410dd53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:35.902261Z",
     "iopub.status.busy": "2024-04-18T19:57:35.902261Z",
     "iopub.status.idle": "2024-04-18T19:57:47.591915Z",
     "shell.execute_reply": "2024-04-18T19:57:47.591726Z",
     "shell.execute_reply.started": "2024-04-18T19:57:35.902261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\embeddings\\azure_openai.py:113: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://qa.gai.cencora.com/aoai to https://qa.gai.cencora.com/aoai/openai.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.azure_openai.AzureChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://qa.gai.cencora.com/aoai to https://qa.gai.cencora.com/aoai/openai.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://qa.gai.cencora.com/aoai to https://qa.gai.cencora.com/aoai/openai.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a126291\\venv\\py311_camelot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eylea is used for the treatment of several eye conditions, including:\n",
      "\n",
      "1. Neovascular (Wet) Age-Related Macular Degeneration (AMD): Eylea is used to treat wet AMD, which is a condition that causes abnormal blood vessel growth in the retina, leading to vision loss.\n",
      "\n",
      "2. Diabetic Retinopathy (DR) in Patients with Diabetic Macular Edema (DME): Eylea is used to treat DR in patients with DME, which is a complication of diabetes that affects the blood vessels in the retina and can lead to vision loss.\n",
      "\n",
      "3. Macular Edema Following Retinal Vein Occlusion (RVO): Eylea is used to treat macular edema, which is swelling in the macula, following RVO, a blockage in the veins that carry blood away from the retina.\n",
      "\n",
      "It is important to note that Eylea should only be administered by a qualified physician.\n"
     ]
    }
   ],
   "source": [
    "from src.util_llm import get_vectorstore_from_doc_chunks, get_conversation_chain\n",
    "from src.config import config\n",
    "\n",
    "vectorstore = get_vectorstore_from_doc_chunks(all_doc_chunks)\n",
    "temp = 0.0\n",
    "conv_chain = get_conversation_chain(vectorstore, temp, config)\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "query = 'what is eylea used for?'\n",
    "\n",
    "response = conv_chain({'question': query, 'chat_history': chat_history})\n",
    "chat_history.append(response['answer'])\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "598becd2-a89a-42a0-8bfa-7c551597292a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.591915Z",
     "iopub.status.busy": "2024-04-18T19:57:47.591915Z",
     "iopub.status.idle": "2024-04-18T19:57:47.595406Z",
     "shell.execute_reply": "2024-04-18T19:57:47.595406Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.591915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'chat_history', 'answer', 'source_documents', 'generated_question'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f017a0e1-717a-46da-9fec-74fecda1200d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.596426Z",
     "iopub.status.busy": "2024-04-18T19:57:47.595406Z",
     "iopub.status.idle": "2024-04-18T19:57:47.608995Z",
     "shell.execute_reply": "2024-04-18T19:57:47.608496Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.596426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is eylea used for?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb38945-b07d-4fb6-9068-7cc9e778a9c6",
   "metadata": {},
   "source": [
    "# Util: HTML Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ebdd2de-2917-48c1-847b-f23856268f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.610094Z",
     "iopub.status.busy": "2024-04-18T19:57:47.609592Z",
     "iopub.status.idle": "2024-04-18T19:57:47.613737Z",
     "shell.execute_reply": "2024-04-18T19:57:47.613737Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.610094Z"
    }
   },
   "outputs": [],
   "source": [
    "notes = r'''\n",
    "ai = https://www.sideshow.com/storage/product-images/2171/c-3po_star-wars_square.jpg\n",
    "human = https://flxt.tmsimg.com/assets/p11759522_i_h9_aa.jpg\n",
    "\n",
    "ai = https://as2.ftcdn.net/v2/jpg/02/38/04/81/1000_F_238048128_OHsRrwAaqeoGCFdpAX6wNgLmGeI0JWFX.jpg\n",
    "human = https://as2.ftcdn.net/v2/jpg/01/38/26/53/1000_F_138265357_dvVPtWBz5VQXBC0j1a5acIxp488Z2XjW.jpg\n",
    "\n",
    "\"https://resizing.flixster.com/ocuc8yjm8Fu5UK5Ze8lbdp58m9Y=/300x300/v2/https://as2.ftcdn.net/v2/jpg/01/38/26/53/1000_F_138265357_dvVPtWBz5VQXBC0j1a5acIxp488Z2XjW.jpg\">\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "589c83a2-6f80-4b2f-8eb3-8f25d44f069b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.613737Z",
     "iopub.status.busy": "2024-04-18T19:57:47.613737Z",
     "iopub.status.idle": "2024-04-18T19:57:47.623632Z",
     "shell.execute_reply": "2024-04-18T19:57:47.623133Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.613737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/html_templates.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/html_templates.py\n",
    "css = '''\n",
    "<style>\n",
    ".chat-message {\n",
    "    padding: 1.5rem;\n",
    "    border-radius: 0.5rem;\n",
    "    margin-bottom: 1rem;\n",
    "    display: flex;\n",
    "    position: relative; /* Added position relative */\n",
    "}\n",
    "\n",
    ".chat-message.user {\n",
    "    background-color: #2b313e;\n",
    "}\n",
    "\n",
    ".chat-message.bot {\n",
    "    background-color: #475063;\n",
    "}\n",
    "\n",
    ".chat-message .avatar {\n",
    "    width: 20%;\n",
    "}\n",
    "\n",
    ".chat-message .avatar img {\n",
    "    max-width: 78px;\n",
    "    max-height: 78px;\n",
    "    border-radius: 50%;\n",
    "    object-fit: cover;\n",
    "}\n",
    "\n",
    ".chat-message .message {\n",
    "    width: 90%;\n",
    "    padding: 0 1rem;\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".small-font {\n",
    "    font-size:16px !important;\n",
    "    color: grey !important;\n",
    "}\n",
    "\n",
    ".css-pxxe24 {\n",
    "    visibility: hidden;\n",
    "}\n",
    "\n",
    "</style>\n",
    "'''\n",
    "\n",
    "bot_template = '''\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n",
    "<div class=\"chat-message bot\">\n",
    "    <div class=\"avatar\">\n",
    "        <img src=\"https://as2.ftcdn.net/v2/jpg/02/38/04/81/1000_F_238048128_OHsRrwAaqeoGCFdpAX6wNgLmGeI0JWFX.jpg\">\n",
    "    </div>\n",
    "    <div class=\"message\">{{MSG}}</div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "user_template = '''\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n",
    "<div class=\"chat-message user\">\n",
    "    <div class=\"avatar\">\n",
    "        <img src=\"https://as1.ftcdn.net/v2/jpg/01/18/59/38/1000_F_118593824_CAAfUDVnd5ZwlCLFWkzUQMaSyLX7h33j.jpg\">\n",
    "    </div>\n",
    "    <div class=\"message\">{{MSG}}</div>\n",
    "</div>\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e9e66-6ddf-4bce-93ff-e52ab66b2aa3",
   "metadata": {},
   "source": [
    "# Util: prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a817948-6047-461c-ba22-f57b60715c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.623632Z",
     "iopub.status.busy": "2024-04-18T19:57:47.623632Z",
     "iopub.status.idle": "2024-04-18T19:57:47.630407Z",
     "shell.execute_reply": "2024-04-18T19:57:47.630407Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.623632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_prompts.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_prompts.py\n",
    "gen_prompt = '''\n",
    "You are a general assistant AI chatbot here to assist the user based on the PDFs they uploaded,\n",
    "and the subsequent openAI embeddings.\n",
    "\n",
    "Please assist the user to the best of your knowledge based on uploads, embeddings and the following user input.\n",
    "If the answer is not available in the uploaded documents, Just say information not available from the input documents.\n",
    "Don't make up unnecessary answers. Only answer based on the uploaded documents.\n",
    "\n",
    "USER INPUT: \n",
    "        '''\n",
    "\n",
    "acc_prompt = '''\n",
    "            You are a academic assistant AI chatbot here to assist the user based on the academic PDFs they uploaded,\n",
    "            and the subsequent openAI embeddings. This academic persona allows you to use as much outside academic responses as you can.\n",
    "            But remember this is an app for academix PDF question. Please respond in as academic a way as possible, with an academix audience in mind\n",
    "            Please assist the user to the best of your knowledge, with this academic persona\n",
    "            based on uploads, embeddings and the following user input. USER INPUT: \n",
    "        '''\n",
    "\n",
    "\n",
    "prompt = gen_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa76c40-b8b0-4ef4-99f1-7e08676444c2",
   "metadata": {},
   "source": [
    "# Util: streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e76ceb-a84e-4bb4-a260-e32713c967df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.630407Z",
     "iopub.status.busy": "2024-04-18T19:57:47.630407Z",
     "iopub.status.idle": "2024-04-18T19:57:47.637118Z",
     "shell.execute_reply": "2024-04-18T19:57:47.637118Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.630407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/util_streamlit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/util_streamlit.py\n",
    "import streamlit as st\n",
    "import base64\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# local imports\n",
    "from src.html_templates import css, bot_template, user_template\n",
    "\n",
    "def display_conversation(prompt):\n",
    "    r\"\"\"Display Conversation\n",
    "\n",
    "    Depends:\n",
    "    ========\n",
    "    - bot_template\n",
    "    - user_template\n",
    "\n",
    "    \"\"\"\n",
    "    with st.container():\n",
    "        for i, this_chat_hist in enumerate(reversed(st.session_state.chat_history)):\n",
    "\n",
    "            question = this_chat_hist.content[len(prompt):]\n",
    "            answer = this_chat_hist.content\n",
    "\n",
    "            if i % 2 == 0: # 0,2,4 etc are Bot answer\n",
    "                st.markdown(bot_template.replace(\"{{MSG}}\", answer), unsafe_allow_html=True)\n",
    "            else: # 1,3,5 etc are User questions\n",
    "                st.markdown(user_template.replace(\"{{MSG}}\", question), unsafe_allow_html=True)\n",
    "\n",
    "def handle_userinput(user_question, prompt):\n",
    "    response = st.session_state.conversation({'question': (prompt+user_question)})\n",
    "    st.session_state.response = response\n",
    "    st.session_state.chat_history = response['chat_history']\n",
    "    st.session_state.prompt_and_question = response['question']\n",
    "    st.session_state.questions.append(st.session_state.prompt_and_question)\n",
    "\n",
    "    # display the conversation\n",
    "    with st.spinner('Generating response...'):\n",
    "        display_conversation(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb2b705-2eb1-435a-b4dc-fd093f8d8236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.637118Z",
     "iopub.status.busy": "2024-04-18T19:57:47.637118Z",
     "iopub.status.idle": "2024-04-18T19:57:47.655401Z",
     "shell.execute_reply": "2024-04-18T19:57:47.654881Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.637118Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf3d44-fa70-4908-b875-54419e1a2e87",
   "metadata": {},
   "source": [
    "# Main App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a295c42a-3167-4613-a5b8-55e82d470e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.656313Z",
     "iopub.status.busy": "2024-04-18T19:57:47.656226Z",
     "iopub.status.idle": "2024-04-18T19:57:47.663259Z",
     "shell.execute_reply": "2024-04-18T19:57:47.663259Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.656313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "# imports\n",
    "import streamlit as st\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import openai\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# local imports\n",
    "from src.html_templates import css, bot_template, user_template\n",
    "from src.util_text import get_lst_text_from_uploaded_file\n",
    "from src.util_doc import get_doc_chunks_from_lst_text\n",
    "from src.util_prompts import gen_prompt\n",
    "from src.util_llm import get_vectorstore_from_doc_chunks, get_conversation_chain\n",
    "from src.util_streamlit import display_conversation\n",
    "from src.util_streamlit import handle_userinput\n",
    "from src.config import config\n",
    "\n",
    "MODEL = 'gpt-35-turbo-16k'\n",
    "TEMP = 0.0\n",
    "prompt = gen_prompt\n",
    "\n",
    "def init_ses_states():\n",
    "    session_states = {\n",
    "        \"conversation\": None,\n",
    "        \"chat_history\": None,\n",
    "        \"questions\": None,\n",
    "        \"prompt_and_question\": \"\",\n",
    "    }\n",
    "    for state, default_value in session_states.items():\n",
    "        if state not in st.session_state:\n",
    "            st.session_state[state] = default_value\n",
    "\n",
    "def process_docs_st(uploaded_files, TEMP, config):\n",
    "    # document is processed only once and a conversation chain is created.\n",
    "    # then, we qa the chain multiple time (we do not process same document multiple times)\n",
    "    st.session_state[\"conversation\"] = None\n",
    "    st.session_state[\"chat_history\"] = None\n",
    "    st.session_state[\"questions\"] = []\n",
    "    st.session_state[\"prompt_and_question\"] = \"\"\n",
    "    st.session_state[\"response\"] = None\n",
    "\n",
    "    all_doc_chunks = []\n",
    "    for i, uploaded_file in enumerate(uploaded_files):\n",
    "        file_name = uploaded_file.name\n",
    "        lst_text = get_lst_text_from_uploaded_file(uploaded_file,ocr=True,pytesseract_path=None)\n",
    "        doc_chunks = get_doc_chunks_from_lst_text(lst_text,file_name)\n",
    "\n",
    "        for doc in doc_chunks:\n",
    "            doc.metadata[\"pdf_number\"] = str(i+1)\n",
    "            all_doc_chunks.append(doc)\n",
    "\n",
    "    vectorstore = get_vectorstore_from_doc_chunks(all_doc_chunks)\n",
    "    conv_chain = get_conversation_chain(vectorstore, temp=TEMP, config=config)\n",
    "\n",
    "    st.session_state.conversation = conv_chain\n",
    "    st.session_state.prompt_and_question = \"\"\n",
    "    st.session_state.pdf_processed = True\n",
    "\n",
    "def sidebar():\n",
    "    global uploaded_files\n",
    "    global config\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.header('Instructions:')\n",
    "        st.write('1. Upload the pdf (scanned or regular)')\n",
    "        st.write('2. Click: Process Files + New Chat')\n",
    "        st.write('3. Start chatting with the chatbot')\n",
    "\n",
    "        # processing\n",
    "        with st.expander(\"Your Documents\", expanded=True):\n",
    "            uploaded_files = st.file_uploader(\"Upload your PDFs here\", accept_multiple_files=True)\n",
    "            if st.button(\"Process Files + New Chat\"):\n",
    "                if uploaded_files:\n",
    "                    # process uploaded files\n",
    "                    with st.spinner(\"Processing\"):\n",
    "                        process_docs_st(uploaded_files, TEMP, config)\n",
    "                else:\n",
    "                    st.caption(\"Please Upload At Least 1 PDF\")\n",
    "                    st.session_state.pdf_processed = False\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Multi-Document Chat Bot\", page_icon=\":books:\")\n",
    "    st.write(css, unsafe_allow_html=True)\n",
    "    global uploaded_files, config\n",
    "\n",
    "    prompt = gen_prompt\n",
    "\n",
    "    init_ses_states()\n",
    "    tabs = st.tabs([\"Chatbot\"] )\n",
    "\n",
    "    # tab: deploy\n",
    "    with tabs[0]:\n",
    "        st.title(\":books: PDF Chatbot\")\n",
    "        st.subheader(\"Created by: Bhishan Poudel\")\n",
    "        sidebar()\n",
    "\n",
    "        # pdf is processed\n",
    "        if st.session_state.get(\"pdf_processed\"):\n",
    "            with st.form(\"user_input_form\"):\n",
    "                user_question = st.text_input(\"Ask a question about your documents:\")\n",
    "                send_button = st.form_submit_button(\"Send\")\n",
    "            if send_button and user_question:\n",
    "                handle_userinput(user_question, prompt)\n",
    "\n",
    "        # pdf is not processed\n",
    "        if not st.session_state.get(\"pdf_processed\"):\n",
    "            st.caption(\"Please Upload Atleast 1 PDF Before Proceeding\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a1dd4-7e9a-46ea-8c03-468c671d89d7",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "609b6170-06a0-4740-b395-6b2da475d4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T20:00:55.169419Z",
     "iopub.status.busy": "2024-04-18T20:00:55.169419Z",
     "iopub.status.idle": "2024-04-18T20:00:55.180821Z",
     "shell.execute_reply": "2024-04-18T20:00:55.180711Z",
     "shell.execute_reply.started": "2024-04-18T20:00:55.169419Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abf15231-f271-4fb9-b8d9-0737d8bb148c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T20:00:02.985824Z",
     "iopub.status.busy": "2024-04-18T20:00:02.984823Z",
     "iopub.status.idle": "2024-04-18T20:00:03.056762Z",
     "shell.execute_reply": "2024-04-18T20:00:03.056038Z",
     "shell.execute_reply.started": "2024-04-18T20:00:02.985824Z"
    }
   },
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# git_bash_path = \"C:/Users/a126291/AppData/Local/Programs/Git/git-bash.exe\"\n",
    "# _ = subprocess.Popen(['start', git_bash_path, '--cd-to-home'], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e5d04c9-1682-4d08-9ef2-79f55bd9ecf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T20:00:20.758377Z",
     "iopub.status.busy": "2024-04-18T20:00:20.758377Z",
     "iopub.status.idle": "2024-04-18T20:00:21.244767Z",
     "shell.execute_reply": "2024-04-18T20:00:21.244767Z",
     "shell.execute_reply.started": "2024-04-18T20:00:20.758377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['explorer.exe', 'C:\\\\Users\\\\a126291\\\\OneDrive - AmerisourceBergen(ABC)\\\\data\\\\pdf_files\\\\fda_drugs'], returncode=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import subprocess\n",
    "# directory_path = r\"C:\\Users\\a126291\\OneDrive - AmerisourceBergen(ABC)\\data\\pdf_files\\fda_drugs\"\n",
    "# subprocess.run(['explorer.exe', directory_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f928021-470a-4459-9d04-902ecf69e3ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:47.688866Z",
     "iopub.status.busy": "2024-04-18T19:57:47.688866Z",
     "iopub.status.idle": "2024-04-18T19:57:47.694047Z",
     "shell.execute_reply": "2024-04-18T19:57:47.694047Z",
     "shell.execute_reply.started": "2024-04-18T19:57:47.688866Z"
    }
   },
   "outputs": [],
   "source": [
    "# !explorer.exe ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
